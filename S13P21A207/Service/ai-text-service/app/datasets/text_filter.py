"""
ë‹¤ì¤‘ ë¼ë²¨ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ë° ì¶”ë¡ 
Author: AI Text Classification System
Python 3.8+ required
"""

import os
import time
import warnings

# í™˜ê²½ ì„¤ì •
os.environ['CUDA_VISIBLE_DEVICES'] = ''  # CPU ì‚¬ìš©
os.environ['USE_TF'] = 'NO'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ["TOKENIZERS_PARALLELISM"] = "false"
warnings.filterwarnings("ignore")

import torch
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import (classification_report, multilabel_confusion_matrix, 
                            f1_score, accuracy_score, hamming_loss)
from transformers import (AutoTokenizer, AutoModelForSequenceClassification, 
                         TrainingArguments, Trainer)
from torch.utils.data import Dataset
import torch.nn as nn

class MultiLabelTextDataset(Dataset):
    """ë‹¤ì¤‘ ë¼ë²¨ í…ìŠ¤íŠ¸ ë¶„ë¥˜ìš© ë°ì´í„°ì…‹"""
    
    def __init__(self, texts, labels, tokenizer, max_length=128):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length
    
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        text = str(self.texts[idx])
        labels = self.labels[idx]
        
        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(labels, dtype=torch.float)
        }

class MultiLabelTrainer(Trainer):
    """ë‹¤ì¤‘ ë¼ë²¨ ë¶„ë¥˜ìš© ì»¤ìŠ¤í…€ íŠ¸ë ˆì´ë„ˆ"""
    
    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):
        labels = inputs.get("labels")
        outputs = model(**inputs)
        logits = outputs.get("logits")
        
        loss_fct = nn.BCEWithLogitsLoss()
        loss = loss_fct(logits, labels)
        
        return (loss, outputs) if return_outputs else loss

def compute_metrics(eval_pred):
    """í‰ê°€ ì§€í‘œ ê³„ì‚°"""
    predictions, labels = eval_pred
    
    sigmoid = torch.nn.Sigmoid()
    probs = sigmoid(torch.Tensor(predictions))
    y_pred = (probs > 0.5).float().numpy()
    y_true = labels
    
    subset_accuracy = accuracy_score(y_true, y_pred)
    hamming = hamming_loss(y_true, y_pred)
    f1_micro = f1_score(y_true, y_pred, average='micro')
    f1_macro = f1_score(y_true, y_pred, average='macro')
    
    return {
        'subset_accuracy': subset_accuracy,
        'hamming_loss': hamming,
        'f1_micro': f1_micro,
        'f1_macro': f1_macro
    }

def predict_multi_label(text, model, tokenizer, device, label_columns, threshold=0.5):
    """ë‹¨ì¼ í…ìŠ¤íŠ¸ ë‹¤ì¤‘ ë¼ë²¨ ì˜ˆì¸¡"""
    
    inputs = tokenizer(
        text,
        truncation=True,
        padding=True,
        max_length=128,
        return_tensors='pt'
    )
    
    inputs = {k: v.to(device) for k, v in inputs.items()}
    
    model.eval()
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        
        probs = torch.sigmoid(logits)
        predictions = (probs > threshold).int()
        
        results = {}
        for i, label in enumerate(label_columns):
            results[label] = {
                'predicted': bool(predictions[0][i]),
                'probability': float(probs[0][i])
            }
    
    return {
        'text': text,
        'predictions': results,
        'predicted_labels': [label for label, info in results.items() if info['predicted']]
    }

def batch_predict_multi_label(texts, model, tokenizer, device, label_columns, threshold=0.5):
    """ë°°ì¹˜ ë©€í‹°ë¼ë²¨ ì˜ˆì¸¡ (ìƒì„¸ ë¡œê·¸ í¬í•¨)"""
    
    results = []
    print(f"ì´ {len(texts)}ê°œ í…ìŠ¤íŠ¸ ì˜ˆì¸¡ ì‹œì‘...")
    print("=" * 80)
    
    for i, text in enumerate(texts):
        result = predict_multi_label(text, model, tokenizer, device, label_columns, threshold)
        results.append(result)
        
        print(f"[{i+1:2d}] {text[:50]}{'...' if len(text) > 50 else ''}")
        pred_labels = result['predicted_labels']
        if pred_labels:
            print(f"     ì˜ˆì¸¡: {', '.join(pred_labels)}")
            for label in pred_labels:
                prob = result['predictions'][label]['probability']
                print(f"       - {label}: {prob:.3f}")
        else:
            print(f"     ì˜ˆì¸¡: CLEAN (ëª¨ë“  ë¼ë²¨ í•´ë‹¹ ì—†ìŒ)")
        
        # ëª¨ë“  ë¼ë²¨ì˜ í™•ë¥  í‘œì‹œ (ë‚®ì€ ê²ƒë„)
        print(f"     ì „ì²´ í™•ë¥ :")
        for label in label_columns:
            prob = result['predictions'][label]['probability']
            status = "âœ“" if result['predictions'][label]['predicted'] else " "
            print(f"       {status} {label}: {prob:.3f}")
        print("-" * 80)
    
    return results

def load_and_prepare_data(csv_path, label_columns):
    """ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬"""
    
    print(f"ë°ì´í„° ë¡œë”©: {csv_path}")
    try:
        df = pd.read_csv(csv_path)
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,}ê°œ ìƒ˜í”Œ")
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
        return None, None, None, None
    
    # ë¼ë²¨ ë¶„í¬ í™•ì¸
    print("\nğŸ“Š ë¼ë²¨ë³„ ë¶„í¬:")
    for col in label_columns:
        positive_count = df[col].sum()
        percentage = positive_count / len(df) * 100
        print(f"{col}: {positive_count}ê°œ ({percentage:.1f}%)")
    
    # ë°ì´í„° ë¶„í• 
    y_labels = df[label_columns].values
    X_train, X_test, y_train, y_test = train_test_split(
        df['text'].values, y_labels, test_size=0.2, random_state=42
    )
    
    print(f"\ní›ˆë ¨ ë°ì´í„°: {len(X_train):,}ê°œ")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test):,}ê°œ")
    
    return X_train, X_test, y_train, y_test

def train_model(X_train, X_test, y_train, y_test, model_name="klue/bert-base", 
                label_columns=None, output_dir='./final_multilabel_model'):
    """ëª¨ë¸ í›ˆë ¨"""
    
    print(f"\nëª¨ë¸ í›ˆë ¨ ì‹œì‘: {model_name}")
    
    # í† í¬ë‚˜ì´ì € ë¡œë”©
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    print("âœ… í† í¬ë‚˜ì´ì € ë¡œë”© ì™„ë£Œ")
    
    # ëª¨ë¸ ë¡œë”©
    model = AutoModelForSequenceClassification.from_pretrained(
        model_name,
        num_labels=len(label_columns),
        problem_type="multi_label_classification"
    )
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ ({device})")
    
    # ë°ì´í„°ì…‹ ìƒì„±
    train_dataset = MultiLabelTextDataset(X_train, y_train, tokenizer)
    test_dataset = MultiLabelTextDataset(X_test, y_test, tokenizer)
    
    # í›ˆë ¨ ì„¤ì •
    training_args = TrainingArguments(
        output_dir='./results',
        num_train_epochs=2,
        per_device_train_batch_size=4,
        per_device_eval_batch_size=8,
        gradient_accumulation_steps=2,
        warmup_steps=200,
        weight_decay=0.01,
        logging_steps=50,
        eval_strategy="steps",
        eval_steps=200,
        save_strategy="steps",
        save_steps=200,
        load_best_model_at_end=True,
        metric_for_best_model="f1_macro",
        greater_is_better=True,
        save_total_limit=2,
        dataloader_pin_memory=False,
        fp16=torch.cuda.is_available(),
        report_to=None,
    )
    
    # íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”
    trainer = MultiLabelTrainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=test_dataset,
        compute_metrics=compute_metrics,
    )
    
    # í›ˆë ¨ ì‹¤í–‰
    print("ğŸš€ í›ˆë ¨ ì‹œì‘...")
    start_time = time.time()
    
    trainer.train()
    
    training_time = time.time() - start_time
    print(f"âœ… í›ˆë ¨ ì™„ë£Œ! ({training_time//60:.0f}ë¶„ {training_time%60:.0f}ì´ˆ)")
    
    # ëª¨ë¸ ì €ì¥
    trainer.save_model(output_dir)
    tokenizer.save_pretrained(output_dir)
    print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥: {output_dir}")
    
    return trainer, model, tokenizer, device

def evaluate_model(trainer, y_test, label_columns):
    """ëª¨ë¸ í‰ê°€"""
    
    print("\nğŸ“Š ëª¨ë¸ í‰ê°€ ì¤‘...")
    
    # ì˜ˆì¸¡
    predictions = trainer.predict(trainer.eval_dataset)
    sigmoid = torch.nn.Sigmoid()
    probs = sigmoid(torch.Tensor(predictions.predictions))
    y_pred = (probs > 0.5).numpy().astype(int)
    y_true = y_test.astype(int)
    
    # ì „ì²´ ì„±ëŠ¥
    subset_accuracy = accuracy_score(y_true, y_pred)
    hamming = hamming_loss(y_true, y_pred)
    f1_micro = f1_score(y_true, y_pred, average='micro')
    f1_macro = f1_score(y_true, y_pred, average='macro')
    
    print(f"\nğŸ“ˆ ì „ì²´ ì„±ëŠ¥:")
    print(f"Subset Accuracy: {subset_accuracy:.4f} ({subset_accuracy*100:.2f}%)")
    print(f"Hamming Loss: {hamming:.4f}")
    print(f"F1 Micro: {f1_micro:.4f}")
    print(f"F1 Macro: {f1_macro:.4f}")
    
    # ë¼ë²¨ë³„ ì„±ëŠ¥
    print(f"\nğŸ·ï¸ ë¼ë²¨ë³„ ì„±ëŠ¥:")
    for i, label in enumerate(label_columns):
        label_f1 = f1_score(y_true[:, i], y_pred[:, i])
        label_accuracy = accuracy_score(y_true[:, i], y_pred[:, i])
        
        true_pos = np.sum((y_true[:, i] == 1) & (y_pred[:, i] == 1))
        false_pos = np.sum((y_true[:, i] == 0) & (y_pred[:, i] == 1))
        false_neg = np.sum((y_true[:, i] == 1) & (y_pred[:, i] == 0))
        
        precision = true_pos / (true_pos + false_pos) if (true_pos + false_pos) > 0 else 0
        recall = true_pos / (true_pos + false_neg) if (true_pos + false_neg) > 0 else 0
        
        print(f"{label:6s}: F1={label_f1:.3f}, Acc={label_accuracy:.3f}, P={precision:.3f}, R={recall:.3f}")
    
    return y_pred, probs

def test_predictions(model, tokenizer, device, label_columns):
    """ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸"""
    
    # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ë“¤
    test_texts = [
        "ì´ê³³ì— í…ŒìŠ¤íŠ¸ í•  í…ìŠ¤íŠ¸ë¥¼",
        "ë°°ì—´ì˜ í˜•ì‹ìœ¼ë¡œ",
        "ë„£ì–´ì£¼ì„¸ìš”"
    ]
    
    print("\nğŸ” ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸:")
    print("=" * 80)
    
    # batch_predict_multi_label ì‚¬ìš©
    start_time = time.time() * 1000
    results = batch_predict_multi_label(test_texts, model, tokenizer, device, label_columns)
    end_time = time.time() * 1000 - start_time
    
    print(f"âœ… ë°°ì¹˜ ì˜ˆì¸¡ ì™„ë£Œ! ì´ ì†Œìš” ì‹œê°„: {end_time:.2f}ms")
    print(f"í‰ê·  ì˜ˆì¸¡ ì‹œê°„: {end_time/len(test_texts):.2f}ms/í…ìŠ¤íŠ¸")
    
    return results

def main(csv_path='../dataset/merged_multilabel_data.csv', model_name="klue/bert-base"):
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("=" * 70)
    print("ğŸ¤– ë‹¤ì¤‘ ë¼ë²¨ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨")
    print("=" * 70)
    
    # ë¼ë²¨ ì •ì˜
    label_columns = ['IN', 'VI', 'SE', 'AD', 'PO', 'CLEAN']
    
    # 1. ë°ì´í„° ë¡œë”©
    X_train, X_test, y_train, y_test = load_and_prepare_data(csv_path, label_columns)
    if X_train is None:
        return
    
    # 2. ëª¨ë¸ í›ˆë ¨
    trainer, model, tokenizer, device = train_model(
        X_train, X_test, y_train, y_test, 
        model_name=model_name, 
        label_columns=label_columns
    )
    
    # 3. ëª¨ë¸ í‰ê°€
    y_pred, probs = evaluate_model(trainer, y_test, label_columns)
    
    # 4. ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
    test_predictions(model, tokenizer, device, label_columns)
    
    print("\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print("ëª¨ë¸ì´ './final_multilabel_model'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return trainer, model, tokenizer, device, label_columns

def quick_predict(text, model_path='./final_multilabel_model'):
    """ì €ì¥ëœ ëª¨ë¸ë¡œ ë¹ ë¥¸ ì˜ˆì¸¡"""
    
    label_columns = ['IN', 'VI', 'SE', 'AD', 'PO', 'CLEAN']
    
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForSequenceClassification.from_pretrained(model_path)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    
    result = predict_multi_label(text, model, tokenizer, device, label_columns)
    return result

if __name__ == "__main__":
    # ê¸°ë³¸ ì‹¤í–‰
    trainer, model, tokenizer, device, label_columns = main()
    
    # ì‚¬ìš© ì˜ˆì‹œ
    # result = quick_predict("ì´ ë°”ë³´ì•¼")
    # print(result)