// src/pages/room/RoomWaiting.tsx
import { useEffect, useRef, useState } from 'react';
import { useNavigate, useParams } from 'react-router-dom';
import { useMediaStore } from '../../stores/useMediaStore';
import Timer from '../../components/common/Timer';
import { useRoom } from '../../hooks/useRooms';
import ButtonWithIcon from '../../components/common/ButtonWithIcon';
import ExitIcon from '../../assets/icons/exit.svg';

import { useRoomContext } from '../../contexts/RoomContext';
import { validateRoomAccess } from '../../utils/roomUtils';

type MD = { deviceId: string; label: string };

export default function RoomWaiting() {
  const { roomId } = useParams<{ roomId: string }>();
  const navigate = useNavigate();
  const { leaveRoom } = useRoomContext();

  const {
    isCameraOn,
    isMicOn,
    // setCameraOn,
    // setMicOn,
    videoDeviceId,
    audioDeviceId,
    setVideoDevice,
    setAudioDevice,
  } = useMediaStore();

  const [cams, setCams] = useState<MD[]>([]);
  const [mics, setMics] = useState<MD[]>([]);
  const [permError, setPermError] = useState<string | null>(null);
  const [isValidating, setIsValidating] = useState(true);

  // í”„ë¦¬ë·°ìš©
  const videoRef = useRef<HTMLVideoElement | null>(null);
  const previewStreamRef = useRef<MediaStream | null>(null);

  // ë§ˆì´í¬ ë ˆë²¨ê³„
  const canvasRef = useRef<HTMLCanvasElement | null>(null);
  const audioCtxRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const micSrcRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const rafRef = useRef<number | null>(null);

  // ì •ë¦¬ ìƒíƒœ ì¶”ì 
  const isCleaningUpRef = useRef(false);
  const isMountedRef = useRef(true);

  // ë°© ì •ë³´ ê°€ì ¸ì˜¤ê¸°
  const { room } = useRoom(roomId || '');

  // ë‚˜ê°€ê¸° ì „ ì •ë¦¬
  const cleanup = () => {
    if (isCleaningUpRef.current) {
      console.log('â¸ï¸ ì´ë¯¸ ì •ë¦¬ ì¤‘, ìŠ¤í‚µ');
      return;
    }

    isCleaningUpRef.current = true;
    console.log('ğŸ§¹ RoomWaiting cleanup ì‹œì‘...');

    try {
      // ì• ë‹ˆë©”ì´ì…˜ í”„ë ˆì„ ì·¨ì†Œ
      if (rafRef.current) {
        cancelAnimationFrame(rafRef.current);
        rafRef.current = null;
      }

      // ì˜¤ë””ì˜¤ ë…¸ë“œë“¤ ì •ë¦¬
      if (micSrcRef.current) {
        try {
          micSrcRef.current.disconnect();
        } catch (e) {
          console.warn('micSrcRef disconnect ì‹¤íŒ¨:', e);
        }
        micSrcRef.current = null;
      }

      if (analyserRef.current) {
        try {
          analyserRef.current.disconnect();
        } catch (e) {
          console.warn('analyserRef disconnect ì‹¤íŒ¨:', e);
        }
        analyserRef.current = null;
      }

      // AudioContext ì •ë¦¬ (ìƒíƒœ í™•ì¸ í›„)
      if (audioCtxRef.current) {
        try {
          if (audioCtxRef.current.state !== 'closed') {
            audioCtxRef.current.close();
            console.log('âœ… AudioContext ì •ë¦¬ ì™„ë£Œ');
          } else {
            console.log('â„¹ï¸ AudioContext ì´ë¯¸ ë‹«í˜€ìˆìŒ');
          }
        } catch (e) {
          console.warn('AudioContext ì •ë¦¬ ì‹¤íŒ¨:', e);
        }
        audioCtxRef.current = null;
      }

      // ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
      if (previewStreamRef.current) {
        previewStreamRef.current.getTracks().forEach((track) => {
          try {
            track.stop();
          } catch (e) {
            console.warn('íŠ¸ë™ ì •ì§€ ì‹¤íŒ¨:', e);
          }
        });
        previewStreamRef.current = null;
      }

      console.log('âœ… RoomWaiting cleanup ì™„ë£Œ');
    } catch (error) {
      console.error('âŒ cleanup ì˜¤ë¥˜:', error);
    }
  };

  // ë¯¸ë””ì–´ ì„¤ì • í•¨ìˆ˜
  const setupMedia = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: true,
        audio: true,
      });

      if (!isMountedRef.current || isCleaningUpRef.current) {
        // ì»´í¬ë„ŒíŠ¸ê°€ ì–¸ë§ˆìš´íŠ¸ë˜ì—ˆë‹¤ë©´ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
        stream.getTracks().forEach((track) => track.stop());
        return;
      }

      previewStreamRef.current = stream;
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        await videoRef.current.play().catch(() => {});
      }

      const devices = await navigator.mediaDevices.enumerateDevices();
      setCams(
        devices
          .filter((d) => d.kind === 'videoinput')
          .map((d) => ({
            deviceId: d.deviceId,
            label: d.label || 'Camera',
          })),
      );
      setMics(
        devices
          .filter((d) => d.kind === 'audioinput')
          .map((d) => ({
            deviceId: d.deviceId,
            label: d.label || 'Microphone',
          })),
      );

      // ì˜¤ë””ì˜¤ ë¶„ì„ê¸° ì„¤ì •
      setupAudioAnalyzer(stream);
    } catch (e) {
      console.error(e);
      setPermError('ì¹´ë©”ë¼/ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
    }
  };

  // ì´ˆê¸° ì„¤ì •
  useEffect(() => {
    const initialize = async () => {
      // ì ‘ê·¼ ê¶Œí•œ ê²€ì¦
      const result = await validateRoomAccess(roomId);

      if (!result.isValid) {
        console.log(`ì ‘ê·¼ ê±°ë¶€: ${result.reason}, /mypageë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸`);
        navigate('/mypage');
        return;
      }

      if (!isMountedRef.current) {
        return;
      }

      setIsValidating(false);

      // ë¯¸ë””ì–´ ì„¤ì •
      await setupMedia();
    };

    initialize();

    return () => {
      isMountedRef.current = false;
      cleanup();
    };
  }, [roomId, navigate]);

  // ì˜¤ë””ì˜¤ ë¶„ì„ê¸° ì„¤ì • í•¨ìˆ˜ (ê°œì„ )
  const setupAudioAnalyzer = (stream: MediaStream) => {
    try {
      // ì´ë¯¸ AudioContextê°€ ìˆë‹¤ë©´ ì •ë¦¬
      if (audioCtxRef.current && audioCtxRef.current.state !== 'closed') {
        audioCtxRef.current.close();
      }

      audioCtxRef.current = new AudioContext();
      analyserRef.current = audioCtxRef.current.createAnalyser();
      analyserRef.current.fftSize = 512;
      micSrcRef.current = audioCtxRef.current.createMediaStreamSource(stream);
      micSrcRef.current.connect(analyserRef.current);

      const draw = () => {
        if (
          isCleaningUpRef.current ||
          !canvasRef.current ||
          !analyserRef.current ||
          !isMountedRef.current
        ) {
          return;
        }

        const c = canvasRef.current;
        const g = c.getContext('2d')!;
        const data = new Uint8Array(analyserRef.current.fftSize);
        analyserRef.current.getByteTimeDomainData(data);
        g.clearRect(0, 0, c.width, c.height);
        g.fillStyle = '#222';
        g.fillRect(0, 0, c.width, c.height);

        let sum = 0;
        for (let i = 0; i < data.length; i++) {
          const v = (data[i] - 128) / 128;
          sum += v * v;
        }
        const rms = Math.sqrt(sum / data.length);
        const level = Math.min(1, rms * 3);
        const barH = level * c.height;
        g.fillStyle = '#FC6C86';
        g.fillRect(0, c.height - barH, c.width, barH);

        if (!isCleaningUpRef.current && isMountedRef.current) {
          rafRef.current = requestAnimationFrame(draw);
        }
      };
      draw();
    } catch (error) {
      console.warn('ì˜¤ë””ì˜¤ ë¶„ì„ê¸° ì„¤ì • ì‹¤íŒ¨:', error);
    }
  };

  // ì¹´ë©”ë¼ ì¼œê¸°/ë„ê¸°
  // const handleCameraToggle = async () => {
  //   if (
  //     !previewStreamRef.current ||
  //     isCleaningUpRef.current ||
  //     !isMountedRef.current
  //   )
  //     return;

  //   const videoTrack = previewStreamRef.current.getVideoTracks()[0];

  //   if (isCameraOn) {
  //     if (videoTrack) {
  //       videoTrack.stop();
  //       previewStreamRef.current.removeTrack(videoTrack);
  //     }
  //     setCameraOn(false);
  //   } else {
  //     try {
  //       const videoStream = await navigator.mediaDevices.getUserMedia({
  //         video: videoDeviceId ? { deviceId: { exact: videoDeviceId } } : true,
  //       });

  //       const newVideoTrack = videoStream.getVideoTracks()[0];
  //       if (newVideoTrack && isMountedRef.current) {
  //         previewStreamRef.current.addTrack(newVideoTrack);

  //         if (videoRef.current) {
  //           videoRef.current.srcObject = previewStreamRef.current;
  //           await videoRef.current.play().catch(() => {});
  //         }
  //       }
  //       setCameraOn(true);
  //     } catch (error) {
  //       console.error('ì¹´ë©”ë¼ ì¼œê¸° ì‹¤íŒ¨:', error);
  //     }
  //   }
  // };

  // ë§ˆì´í¬ ì¼œê¸°/ë„ê¸°
  // const handleMicToggle = async () => {
  //   if (
  //     !previewStreamRef.current ||
  //     isCleaningUpRef.current ||
  //     !isMountedRef.current
  //   )
  //     return;

  //   const audioTrack = previewStreamRef.current.getAudioTracks()[0];

  //   if (isMicOn) {
  //     if (audioTrack) {
  //       audioTrack.stop();
  //       previewStreamRef.current.removeTrack(audioTrack);
  //       if (micSrcRef.current) {
  //         try {
  //           micSrcRef.current.disconnect();
  //         } catch (e) {
  //           console.warn('micSrcRef disconnect ì‹¤íŒ¨:', e);
  //         }
  //         micSrcRef.current = null;
  //       }
  //     }
  //     setMicOn(false);
  //   } else {
  //     try {
  //       const audioStream = await navigator.mediaDevices.getUserMedia({
  //         audio: audioDeviceId ? { deviceId: { exact: audioDeviceId } } : true,
  //       });

  //       const newAudioTrack = audioStream.getAudioTracks()[0];
  //       if (newAudioTrack && isMountedRef.current) {
  //         previewStreamRef.current.addTrack(newAudioTrack);

  //         if (
  //           audioCtxRef.current &&
  //           analyserRef.current &&
  //           audioCtxRef.current.state === 'running'
  //         ) {
  //           try {
  //             micSrcRef.current = audioCtxRef.current.createMediaStreamSource(
  //               previewStreamRef.current,
  //             );
  //             micSrcRef.current.connect(analyserRef.current);
  //           } catch (e) {
  //             console.warn('ì˜¤ë””ì˜¤ ë¶„ì„ê¸° ì¬ì—°ê²° ì‹¤íŒ¨:', e);
  //           }
  //         }
  //       }
  //       setMicOn(true);
  //     } catch (error) {
  //       console.error('ë§ˆì´í¬ ì¼œê¸° ì‹¤íŒ¨:', error);
  //     }
  //   }
  // };

  // ë””ë°”ì´ìŠ¤ ë³€ê²½ ì²˜ë¦¬
  const handleVideoDeviceChange = async (deviceId: string) => {
    setVideoDevice(deviceId || undefined);

    if (
      !isCameraOn ||
      !previewStreamRef.current ||
      isCleaningUpRef.current ||
      !isMountedRef.current
    )
      return;

    try {
      const oldVideoTrack = previewStreamRef.current.getVideoTracks()[0];
      if (oldVideoTrack) {
        oldVideoTrack.stop();
        previewStreamRef.current.removeTrack(oldVideoTrack);
      }

      const videoStream = await navigator.mediaDevices.getUserMedia({
        video: deviceId ? { deviceId: { exact: deviceId } } : true,
      });

      const newVideoTrack = videoStream.getVideoTracks()[0];
      if (newVideoTrack && isMountedRef.current) {
        previewStreamRef.current.addTrack(newVideoTrack);

        if (videoRef.current) {
          videoRef.current.srcObject = previewStreamRef.current;
          await videoRef.current.play().catch(() => {});
        }
      }
    } catch (error) {
      console.error('ë¹„ë””ì˜¤ ë””ë°”ì´ìŠ¤ ë³€ê²½ ì‹¤íŒ¨:', error);
    }
  };

  const handleAudioDeviceChange = async (deviceId: string) => {
    setAudioDevice(deviceId || undefined);

    if (
      !isMicOn ||
      !previewStreamRef.current ||
      isCleaningUpRef.current ||
      !isMountedRef.current
    )
      return;

    try {
      const oldAudioTrack = previewStreamRef.current.getAudioTracks()[0];
      if (oldAudioTrack) {
        oldAudioTrack.stop();
        previewStreamRef.current.removeTrack(oldAudioTrack);
        if (micSrcRef.current) {
          try {
            micSrcRef.current.disconnect();
          } catch (e) {
            console.warn('micSrcRef disconnect ì‹¤íŒ¨:', e);
          }
          micSrcRef.current = null;
        }
      }

      const audioStream = await navigator.mediaDevices.getUserMedia({
        audio: deviceId ? { deviceId: { exact: deviceId } } : true,
      });

      const newAudioTrack = audioStream.getAudioTracks()[0];
      if (newAudioTrack && isMountedRef.current) {
        previewStreamRef.current.addTrack(newAudioTrack);

        if (
          audioCtxRef.current &&
          analyserRef.current &&
          audioCtxRef.current.state === 'running'
        ) {
          try {
            micSrcRef.current = audioCtxRef.current.createMediaStreamSource(
              previewStreamRef.current,
            );
            micSrcRef.current.connect(analyserRef.current);
          } catch (e) {
            console.warn('ì˜¤ë””ì˜¤ ë¶„ì„ê¸° ì¬ì—°ê²° ì‹¤íŒ¨:', e);
          }
        }
      }
    } catch (error) {
      console.error('ì˜¤ë””ì˜¤ ë””ë°”ì´ìŠ¤ ë³€ê²½ ì‹¤íŒ¨:', error);
    }
  };

  const enterMeeting = () => navigate(`/meeting/${roomId}`);

  // ê°œì„ ëœ ë°© ë‚˜ê°€ê¸° í•¨ìˆ˜
  const exitMeeting = () => {
    console.log('ğŸšª RoomWaitingì—ì„œ ë°© ë‚˜ê°€ê¸° ì‹œì‘');
    cleanup(); // ë¡œì»¬ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
    leaveRoom(); // Contextì˜ leaveRoom ì‚¬ìš©
  };

  // ê²€ì¦ ì¤‘ì¼ ë•Œ ë¡œë”© í™”ë©´
  if (isValidating) {
    return (
      <div className="w-full min-h-screen bg-my-black flex items-center justify-center">
        <div className="text-my-white text-xl">ì ‘ê·¼ ê¶Œí•œì„ í™•ì¸í•˜ëŠ” ì¤‘...</div>
      </div>
    );
  }

  return (
    <div className="w-full min-h-screen bg-my-black flex flex-col">
      {/* ìƒë‹¨ í—¤ë” ì˜ì—­ */}
      <div className="flex items-center justify-between p-6">
        {/* ì™¼ìª½ íƒ€ì´ë¨¸ */}
        <div className="bg-watermelon rounded-3xl min-w-24 px-4 py-2 text-my-black text-center font-bold text-xl">
          <Timer
            endTime={room?.scheduledTime || null}
            onExpire={enterMeeting}
          />
        </div>

        {/* ì¤‘ì•™ ì œëª© */}
        <h1 className="text-my-white text-2xl font-medium">
          ì¹´ë©”ë¼ / ì˜¤ë””ì˜¤ ìƒíƒœ ì ê²€
        </h1>

        {/* ì˜¤ë¥¸ìª½ í‡´ì¥ ë²„íŠ¼ */}
        <div className="ml-12">
          <ButtonWithIcon onClick={exitMeeting} size="w-7 h-7">
            <img src={ExitIcon} alt="Exit" />
          </ButtonWithIcon>
        </div>
      </div>

      {/* ë©”ì¸ ì½˜í…ì¸  ì˜ì—­ */}
      <div className="flex-1 flex flex-col xl:flex-row gap-6 p-6">
        {/* ë¹„ë””ì˜¤ í”„ë¦¬ë·° ì˜ì—­ */}
        <div className="flex-1 flex flex-col items-center">
          <div className="w-full max-w-4xl">
            {permError ? (
              <div className="w-full aspect-video flex text-watermelon text-xl items-center justify-center text-center bg-my-black rounded-3xl border-2 border-watermelon">
                {permError}
              </div>
            ) : (
              <video
                ref={videoRef}
                playsInline
                muted
                className="w-full aspect-video object-cover rounded-3xl border-2 border-watermelon scale-x-[-1]"
              />
            )}
          </div>
        </div>

        {/* ì»¨íŠ¸ë¡¤ íŒ¨ë„ */}
        <div className="h-full min-w-0 flex flex-col items-stretch justify-between gap-6">
          <div className="flex flex-col justify-between gap-3">
            <label className="block">
              <div className="mb-1 text-xl">ì¹´ë©”ë¼</div>
              <select
                value={videoDeviceId || ''}
                onChange={(e) => handleVideoDeviceChange(e.target.value)}
                className="w-full bg-my-black rounded-full p-2 pr-8 
                  ring-1 ring-watermelon focus:ring-2 focus:ring-watermelon outline-none"
              >
                <option value="">ê¸°ë³¸</option>
                {cams.map((d) => (
                  <option key={d.deviceId} value={d.deviceId}>
                    {d.label}
                  </option>
                ))}
              </select>
            </label>

            <label className="block">
              <div className="mb-1 text-xl">ë§ˆì´í¬</div>
              <select
                value={audioDeviceId || ''}
                onChange={(e) => handleAudioDeviceChange(e.target.value)}
                className="w-full bg-my-black rounded-full p-2 pr-8 
                  ring-1 ring-watermelon focus:ring-2 focus:ring-watermelon outline-none"
              >
                <option value="">ê¸°ë³¸</option>
                {mics.map((d) => (
                  <option key={d.deviceId} value={d.deviceId}>
                    {d.label}
                  </option>
                ))}
              </select>
            </label>

            <div>
              <label className="block mb-2 font-medium text-xl">
                ë§ˆì´í¬ ì…ë ¥ ë ˆë²¨
              </label>
              <canvas
                ref={canvasRef}
                width={220}
                height={30}
                className="w-full bg-gray-700 rounded-3xl border border-watermelon"
              />
            </div>
          </div>

          {/* í•˜ë‹¨ ì»¨íŠ¸ë¡¤ ë²„íŠ¼ë“¤ */}
          <div className="flex justify-center space-x-4">
            {/* <ButtonWithIcon onClick={handleCameraToggle}>
              {isCameraOn ? (
                <img
                  src={CamOnIcon}
                  alt="Camera On"
                  className="w-12 h-12 p-1"
                />
              ) : (
                <img
                  src={CamOffIcon}
                  alt="Camera Off"
                  className="w-12 h-12 p-1"
                />
              )}
            </ButtonWithIcon>
            <ButtonWithIcon onClick={handleMicToggle}>
              {isMicOn ? (
                <img src={MicOnIcon} alt="Mic On" className="w-12 h-12 p-1" />
              ) : (
                <img src={MicOffIcon} alt="Mic Off" className="w-12 h-12 p-1" />
              )}
            </ButtonWithIcon> */}

            {/* TODO: ì‚­ì œ */}
            {/* <FilledButton
              label="íšŒì˜ ì…ì¥"
              onClick={enterMeeting}
              size="text-lg px-4"
            /> */}
          </div>
        </div>
      </div>
    </div>
  );
}
